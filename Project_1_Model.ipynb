{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIwW_EWlYjTT"
      },
      "source": [
        "# **Installation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1aRbhQ1zVn4",
        "scrolled": true,
        "outputId": "812b06f9-a8dc-4cfb-dc91-b22bf92ab9f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "pip install statsmodels --upgrade"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: statsmodels in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.1 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->statsmodels) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5->statsmodels) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdXapcCJPIIx"
      },
      "source": [
        "# **Preprocess**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIKXOZWMNM3f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "from datetime import datetime\n",
        "import io\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "path = './'\n",
        "split_csv_folder = path + 'split_csv_country/'\n",
        "\n",
        "if not os.path.exists(split_csv_folder):\n",
        "  os.makedirs(split_csv_folder)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrjx1KmziQDr"
      },
      "source": [
        "def mape(actual, pred): \n",
        "  actual, pred = np.array(actual), np.array(pred)\n",
        "  return np.mean(np.abs((actual - pred) / (actual + (actual==0)))) * 100"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnHeLQLzXHVo"
      },
      "source": [
        "train = read_csv(path + 'download.csv')\n",
        "train = train.drop(columns = ['countryterritoryCode', 'geoId'])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hldKIObXKHw"
      },
      "source": [
        "# load data\n",
        "# import csv to dataframe and drop unneccessary columns\n",
        "train.index.name = 'date'\n",
        "\n",
        "# mark all NA values with 0\n",
        "train['cases'].fillna(0, inplace=True)\n",
        "train['deaths'].fillna(0, inplace=True)\n",
        "train['popData2019'].fillna(0, inplace=True)\n",
        "train['Cumulative_number_for_14_days_of_COVID-19_cases_per_100000'].fillna(0, inplace=True)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N0Ci67ktMPh"
      },
      "source": [
        "# save to file\n",
        "train.to_csv(path + 'proprocessed_data.csv')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipw8R7F0XRy0"
      },
      "source": [
        "columnName = ['dateRep', 'day', 'month', 'year', 'cases', 'deaths', 'popData2019', 'Cumulative_number_for_14_days_of_COVID-19_cases_per_100000']\n",
        "train = read_csv(path + 'proprocessed_data.csv')\n",
        "for ctr, group in train.groupby(['countriesAndTerritories']):\n",
        "  group.to_csv((split_csv_folder + ctr + \".csv\"), columns = columnName, index = False) "
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8Yr2gqyXTmT"
      },
      "source": [
        "# preprocess of csv data\n",
        "for file in os.listdir(split_csv_folder):\n",
        "  if file.endswith(\".csv\"):\n",
        "    df = pd.read_csv(split_csv_folder + file)\n",
        "    for index, row in df.iterrows():\n",
        "       if row['cases'] < 0:\n",
        "         row['cases'] = -row['cases']\n",
        "    df.to_csv(split_csv_folder + file, index = False)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSnvNUeHiuhr"
      },
      "source": [
        "# **Create new csv for saving result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8TtQBLwi8J4"
      },
      "source": [
        "result_df = pd.DataFrame({'':['10/9', '10/10', '10/11', '10/12', '10/13', '10/14', '10/15', 'MAPE']})\n",
        "for file in os.listdir(split_csv_folder):\n",
        "  if (file == 'Russia.csv') or (file == 'Greece.csv') or (file == 'India.csv') or (file == 'United_States_of_America.csv') or (file == 'Turkey.csv'):\n",
        "    result_df[file[:-4]] = ''\n",
        "result_df.to_csv(path + 'result_regenerated.csv', index = False)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60Ry0LMbMORU"
      },
      "source": [
        "# **Autoregression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IStDw-TdZjsO"
      },
      "source": [
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from matplotlib import pyplot\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "model_para = {}\n",
        "\n",
        "for file in os.listdir(split_csv_folder):\n",
        "  if (file == 'Russia.csv') or (file == 'Greece.csv') or (file == 'India.csv') or (file == 'United_States_of_America.csv') or (file == 'Turkey.csv'):\n",
        "    df = pd.read_csv(split_csv_folder + file, header=0, index_col=0)\n",
        "    if (file == 'Cases_on_an_international_conveyance_Japan.csv'):\n",
        "      for t in range(0, 7):\n",
        "        result_df[file[:-4]].loc[t] = 0\n",
        "    else:\n",
        "      df = df.reindex(index = df.index[::-1])\n",
        "      X = df['cases'].values\n",
        "      X = X.astype('float32')\n",
        "      min = 1000000\n",
        "      opt_lag = -1\n",
        "      train = X[: len(X) - 10]\n",
        "      test = X[len(X) - 10:]\n",
        "      \n",
        "      try_range = 50\n",
        "      if len(X[: len(X) - 10]) < 50:\n",
        "        try_range = len(X[: len(X) - 10])\n",
        "\n",
        "      for i in range(1, try_range):\n",
        "        # train autoregression\n",
        "        window = i\n",
        "        model = AutoReg(train, lags=window, old_names=False)\n",
        "        model_fit = model.fit()\n",
        "        coef = model_fit.params\n",
        "        # walk forward over time steps in test\n",
        "        history = train[len(train)-window:]\n",
        "        history = [history[idx] for idx in range(len(history))]\n",
        "        predictions = list()\n",
        "        for t in range(len(test)):\n",
        "          length = len(history)\n",
        "          lag = [history[idx] for idx in range(length-window,length)]\n",
        "          yhat = coef[0]\n",
        "          for d in range(window):\n",
        "            yhat += coef[d+1] * lag[window-d-1]\n",
        "          predictions.append(yhat)\n",
        "          history.append(yhat)\n",
        "        mp = mape(test, predictions)\n",
        "        if mp < min:\n",
        "          opt_lag = i\n",
        "          min = mp\n",
        "      model_para[file[:-4] + '_mape'] = min\n",
        "      model_para[file[:-4] + '_lag'] = opt_lag\n",
        "      train = X[: len(X) - 10]\n",
        "      model = AutoReg(train, lags=opt_lag, old_names=False)\n",
        "      model_fit = model.fit()\n",
        "      coef = model_fit.params\n",
        "      history = X[len(X)-opt_lag:]\n",
        "      history = [history[i] for i in range(len(history))]\n",
        "      # walk forward over time steps in test\n",
        "      for t in range(0, 7):\n",
        "        length = len(history)\n",
        "        lag = [history[i] for i in range(length-opt_lag,length)]\n",
        "        yhat = coef[0]\n",
        "        for d in range(opt_lag):\n",
        "          yhat += coef[d+1] * lag[opt_lag-d-1]\n",
        "        history.append(yhat)\n",
        "        if yhat < 0:\n",
        "          yhat = 0\n",
        "        result_df[file[:-4]].loc[t] = round(yhat)\n",
        "      result_df[file[:-4]].loc[7] = min\n",
        "      result_df.to_csv(path + 'result_regenerated.csv', index = False)\n",
        "      # pyplot.plot(test[:7])\n",
        "      # pyplot.plot(result_df[file[:-4]], color='red')\n",
        "      # pyplot.show()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGNwEctqoghF"
      },
      "source": [
        ""
      ],
      "execution_count": 56,
      "outputs": []
    }
  ]
}